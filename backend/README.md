# OmniRL Backend API

FastAPI backend for visuAI image understanding with OmniRL vision-language model.

## ğŸš€ Quick Start

### Setup

1. **Create virtual environment:**
```bash
cd backend
python -m venv venv
```

2. **Activate environment:**
```bash
# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Configure environment:**
```bash
# Copy example env file
copy .env.example .env

# Edit .env with your settings
```

5. **Run the server:**
```bash
python main.py
```

Server will start at `http://localhost:8000`

## ğŸ“– API Documentation

Once the server is running, visit:
- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

## ğŸ”Œ Endpoints

### Health Check
```http
GET /api/health
```

### Generate Description
```http
POST /api/describe
Content-Type: application/json

{
  "predictions": [
    {"className": "laptop", "probability": 0.9},
    {"className": "desk", "probability": 0.3}
  ]
}
```

### Ask Question
```http
POST /api/ask
Content-Type: application/json

{
  "predictions": [
    {"className": "cat", "probability": 0.95}
  ],
  "question": "What animal is in the image?"
}
```

## ğŸ§ª Testing

### Using curl:

```bash
# Health check
curl http://localhost:8000/api/health

# Describe image
curl -X POST http://localhost:8000/api/describe \
  -H "Content-Type: application/json" \
  -d "{\"predictions\": [{\"className\": \"laptop\", \"probability\": 0.9}]}"

# Ask question
curl -X POST http://localhost:8000/api/ask \
  -H "Content-Type: application/json" \
  -d "{\"predictions\": [{\"className\": \"cat\", \"probability\": 0.95}], \"question\": \"What animal is this?\"}"
```

## ğŸ”§ Configuration

Edit `.env` file:

```env
# Server
PORT=8000
HOST=0.0.0.0

# CORS (add your frontend URL)
ALLOWED_ORIGINS=http://localhost:4200

# Model (set to false when OmniRL is trained)
USE_MOCK_RESPONSES=true
```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env                    # Configuration
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”œâ”€â”€ services/
â”‚   â””â”€â”€ omni_service.py    # OmniRL service
â””â”€â”€ training/
    â”œâ”€â”€ prepare_data.py    # Data preparation
    â””â”€â”€ train_omni.py      # Model training
```

## ğŸ¯ Current Status

âœ… **Phase 1 Complete:**
- FastAPI structure created
- Mock responses for testing
- CORS configured
- API documentation

â³ **Next Steps:**
- Train OmniRL model
- Replace mock responses
- Optimize inference speed

## ğŸ› Troubleshooting

**Port already in use:**
```bash
# Change PORT in .env file
PORT=8001
```

**CORS errors:**
```bash
# Add your frontend URL to .env
ALLOWED_ORIGINS=http://localhost:4200,http://localhost:4201
```

**Module not found:**
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```
